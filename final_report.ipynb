{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418f70d-58db-448f-9ea7-b764d36b9e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(readxl)\n",
    "install.packages(\"gsheet\")\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(digest)\n",
    "library(infer)\n",
    "library(cowplot)\n",
    "library(broom)\n",
    "library(GGally)\n",
    "library(AER)\n",
    "library(gsheet)\n",
    "library(gridExtra)\n",
    "library(leaps)\n",
    "library(glmnet)\n",
    "library(mltools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d289734e-e2ef-46de-825e-e74ee66582c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for notebook\n",
    "set.seed(7777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54506e7-bef2-4a1a-a6dc-c40458198f7a",
   "metadata": {},
   "source": [
    "# How Spotify Song Attributes Affect Valence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9956f49-8b60-4164-bcc3-e61621e8134f",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364c720-d485-4e82-9cdc-61522e8ddc2e",
   "metadata": {},
   "source": [
    "\n",
    "Starting from infancy and all throughout one's life, listening to music is an activity that the majority of people engage in. Music has been shown to have effects on our daily functioning and overall well-being (Groarke & Hogan, 2018). In particular, how positive or how negative a song sounds plays a critical role in determining how someone will be affected by listening to it. For example, listening to positive sounding music increases self-confidence (Tajadura-Jiménez, 2011) and can help relieve pain (Roy, Peretz, & Rainville, 2008). This musical positiveness present in a song is referred to as its valence, so a song that sounds cheerful and upbeat is said to have high valence (close to 1 in our case). \n",
    "\n",
    "Music today is becoming more and more accessible as people can choose what they listen to on the radio, youtube, or on one of the many available streaming services. Currently, Spotify is the world’s most popular music streaming service with over 365 million monthly users (2021). We will be using a dataset containing 232725 songs available on Spotify that contains information about each song such as its genre, danceability, loudness, acousticness, and valence (among others). Our goals are to predict the valence of a song from its other attributes and determine what qualities of a song impact our emotional perception. Therefore, our project will focus on both inference and prediction. First, we will determine which features of the song are most related to its valence, and using these features as our explanatory variables, we will try to build a model to predict a song’s valence.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf703421-6553-424a-a8a4-187f1d5cb631",
   "metadata": {},
   "source": [
    "## Methods & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b9539e-645b-4682-8ada-4b14ab5b2e6f",
   "metadata": {},
   "source": [
    "### Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f988b52-4746-476f-a3bc-67ba8fcbebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and drop any na values in the dataset.\n",
    "df <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1fnNjFKFZmGgavOYezz-swtQICqWyAMMZxs2H6Nsk29M/edit#gid=2110346216')\n",
    "df = drop_na(df)\n",
    "print(\"Table 1: Spotify Dataset\")\n",
    "head(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c10a1a-11ac-4d3a-96f4-48ee6d16bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features from the dataset, removing metadata such as artist_name, track_name etc.\n",
    "spotify = df %>% select(-artist_name,  -track_name, -track_id, -duration_ms)\n",
    "print(\"Table 2: Spotify Dataset without metadata\")\n",
    "head(spotify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33d74b-4ab8-4fd5-8586-a792d93b8e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of valence across all genres\n",
    "# Note that the response variable is on the x-axis, this was done because due to the amount of different genres, having genre on the x axis\n",
    "# made the labels difficult to read, even with rotated text.\n",
    "options(repr.plot.width = 10, repr.plot.height = 11)\n",
    "genre_plot = df %>%\n",
    "ggplot() +\n",
    "geom_boxplot(aes(y = genre, x = valence)) + \n",
    "labs(x = \"Valence of Songs\", y = \"Song Genres\", title = \"Figure 1: Valence distribution in songs by Genre\")\n",
    "\n",
    "genre_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ded93-40ee-4c0e-8801-0a19213a9d7d",
   "metadata": {},
   "source": [
    "We have a wide variety of distributions for valence over different levels of genre, so it might be worthwhile to explore how the relationship between our predictive variables and the response is affected by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b2ca6-7fba-42ea-a531-97c5cd346538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of valence among different levels of categorical features, note that the response variable(valence) is plotted on the y axis from here onwards\n",
    "options(repr.plot.width = 18, repr.plot.height = 8)\n",
    "mode_plot = spotify %>%\n",
    "ggplot() +\n",
    "geom_boxplot(aes(y = valence, x = mode)) + \n",
    "labs(x = \"Mode of Songs\", y = \"Valence of Songs\", title = \"Figure 2: Valence distribution in songs by Mode\")\n",
    "\n",
    "key_plot = spotify %>%\n",
    "ggplot() +\n",
    "geom_boxplot(aes(y = valence, x = key)) + \n",
    "labs(x = \"Key of Songs\", y = \"Valence of Songs\", title = \"Figure 3: Valence distribution in songs by Key\")\n",
    "\n",
    "t_plot = spotify %>%\n",
    "ggplot() +\n",
    "geom_boxplot(aes(y = valence, x = time_signature)) + \n",
    "labs(x = \"Time Signature of Songs\", y = \"Valence of Songs\", title = \"Figure 4: Valence distribution in songs by Time Signature\")\n",
    "\n",
    "\n",
    " plot_grid(mode_plot, key_plot, t_plot,\n",
    "   ncol = 3\n",
    " )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294096d-4538-46bf-92f2-8b9a2323e0cc",
   "metadata": {},
   "source": [
    "The distribution of valence seems almost identical across different modes, varies slightly across different keys, and varies moderately across different time signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b7afe-0d05-4c5d-b5fa-6251dd613a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the correlation between valence and numeric variables\n",
    "# Note that running ggpairs with all the numeric variables was causing the kernel to timeout, so a random subsample of 1000 was used for visualization purposes\n",
    "options(repr.plot.width = 25, repr.plot.height = 18)\n",
    "pairs_plot = spotify %>%\n",
    "            select(-genre, -key, -mode, -time_signature) %>%\n",
    "            sample_n(size = 1000, replace = FALSE) %>%\n",
    "            ggpairs(lower=list(combo=wrap(\"facethist\", binwidth=0.8))) + ggtitle(\"Figure 5: Correlation Between Different Variables\")\n",
    "\n",
    "pairs_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370f6f19-bcb1-475c-9804-4853c35f6631",
   "metadata": {},
   "source": [
    "Energy and loudness appear to be highly positively correlated (0.826) compared to the rest of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed8c4a-380d-46f9-bd2e-b7b1ebcaa206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a correlation matrix to examine the relationship between predictive variables\n",
    "corr_matrix_sample <- spotify %>%\n",
    "  select(-genre, -key, -mode, -time_signature) %>%\n",
    "  cor() %>%\n",
    "  as.data.frame() %>%\n",
    "  rownames_to_column(\"var1\") %>%\n",
    "  pivot_longer(-var1, names_to = \"var2\", values_to = \"corr\")\n",
    "\n",
    "plot_corr_matrix_sample <- corr_matrix_sample %>%\n",
    "  ggplot(aes(x = var1, y = var2)) +\n",
    "  geom_tile(aes(fill = corr), color = \"white\") +\n",
    "  scale_fill_distiller(\"Correlation Coefficient \\n\",\n",
    "    palette = 'YlOrRd',\n",
    "    direction = 1, limits = c(-1, 1)\n",
    "  ) +\n",
    "  labs(x = \"\", y = \"\", title = \"Figure 6. Correlational Matrix Heatmap\") +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    axis.text.x = element_text(\n",
    "      angle = 45, vjust = 1,\n",
    "      size = 18, hjust = 1\n",
    "    ),\n",
    "    axis.text.y = element_text(\n",
    "      vjust = 1,\n",
    "      size = 18, hjust = 1\n",
    "    ),\n",
    "    legend.title = element_text(size = 18, face = \"bold\"),\n",
    "    legend.text = element_text(size = 18),\n",
    "    legend.key.size = unit(2, \"cm\")\n",
    "  ) +\n",
    "  coord_fixed() +\n",
    "  geom_text(aes(x = var1, y = var2, label = round(corr, 2)), color = \"black\", size = 6)\n",
    "plot_corr_matrix_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f02c3-7a6f-49df-9d04-81280c30ee18",
   "metadata": {},
   "source": [
    "To determine if loudness and energy may be contributing to multicollinearity, we will first perform feature selection to see if they are relevant for predicting valence. Then, based on the Variance Inflation Factors, we will assess which model may be most effective for predicting new song valences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134958e-b7d0-40e5-9d63-714d69ca9c6a",
   "metadata": {},
   "source": [
    "### Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b592f-5d24-4de1-96d5-b55b5b13ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing categorical variables in the dataset, while it would have been nice to include these, our kernel \n",
    "# would either end up dying when we tried to fit our models or the output would be too complex to interpret due to the \n",
    "# amount of levels they introduced.\n",
    "spotify <- spotify %>% select(-genre, -key, -mode, -time_signature)\n",
    "\n",
    "# Splitting the dataset to avoid bias\n",
    "spotify_split <- sample(rep(1:3, diff(floor(nrow(spotify) * c(0, 0.6, 0.8, 1)))))\n",
    "\n",
    "# For the model\n",
    "inference <- spotify[spotify_split==1,]\n",
    "\n",
    "# For variable selection\n",
    "selection <- spotify[spotify_split==2,]\n",
    "\n",
    "# For testing our model\n",
    "prediction_df <- spotify[spotify_split==3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b567ed-3f7f-4c3f-a61c-7967a41c0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table 3: Dataset for Feature Selection\")\n",
    "head(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04649586-d07a-4772-a0b0-ad7d83a0e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run feature selection, using both forward and backward selection\n",
    "spotify_sample_forward <- regsubsets(\n",
    "  x = valence ~.,\n",
    "  data = selection, nvmax = 50, method = \"forward\",\n",
    ")\n",
    "\n",
    "fwd_summary <- summary(spotify_sample_forward)\n",
    "\n",
    "fwd_summary_df <- data.frame(\n",
    "    RSQ = fwd_summary$rsq,\n",
    "    RSS = fwd_summary$rss,\n",
    "    ADJ.R2 = fwd_summary$adjr2,\n",
    "    BIC = fwd_summary$bic\n",
    ")\n",
    "\n",
    "spotify_sample_backward <- regsubsets(\n",
    "  x = valence ~.,\n",
    "  data = selection, nvmax = 50, method = \"backward\",\n",
    ")\n",
    "\n",
    "\n",
    "back_summary <- summary(spotify_sample_backward)\n",
    "\n",
    "back_summary_df <- data.frame(\n",
    "    RSQ = back_summary$rsq,\n",
    "    RSS = back_summary$rss,\n",
    "    ADJ.R2 = back_summary$adjr2,\n",
    "    BIC = back_summary$bic\n",
    ")\n",
    "print(\"Table 4: Summary of Models with different number of input variables selected by forward selection\")\n",
    "fwd_summary_df\n",
    "print(\"Table 5: Summary of Models with different number of input variables selected by backward selection\")\n",
    "back_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620484eb-e44f-4d24-9512-b486ad7de255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making scatter graphs to compare mallow's cp for the different models, so that we can pick the one with least apparent bias.\n",
    "fwd_candidates <- tibble(\n",
    "  n_input_variables = 1:9,\n",
    "  C_p = fwd_summary$cp\n",
    ")\n",
    "fwd_plot = fwd_candidates %>%\n",
    "            ggplot() +\n",
    "            geom_point(aes(y = C_p, x = n_input_variables)) +\n",
    "            labs(x = \"Number of Input Variables\",\n",
    "                y = \"Mallows' CP\", \n",
    "                title = \"Figure 7: Mallows' CP for Models with different number of input variables selected by forward selection\")\n",
    "\n",
    "\n",
    "back_candidates <- tibble(\n",
    "  n_input_variables = 1:9,\n",
    "  C_p = back_summary$cp\n",
    ")\n",
    "back_plot =  back_candidates %>%\n",
    "            ggplot() +\n",
    "            geom_point(aes(y = C_p, x = n_input_variables)) +\n",
    "            labs(x = \"Number of Input Variables\",\n",
    "                y = \"Mallows' CP\",\n",
    "                title = \"Figure 8: Mallows' CP Models with different number of input variables selected by backward selection\")\n",
    "\n",
    " plot_grid(fwd_plot, back_plot,\n",
    "   ncol = 2\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0b1bb-c1d8-4926-aa8b-7a95ca1554c9",
   "metadata": {},
   "source": [
    "Looking at these values, we can see that Mallow's cp is lowest with all the predictors whether we do forward or backward selection, thus we will not remove any variables from our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e928212-f936-480f-b6ad-db75dd650a6b",
   "metadata": {},
   "source": [
    "### Variable Selection using Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a9614-54e8-42b0-856e-086f7ae50e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running Feature selection using Lasso\n",
    "lasso_model <-\n",
    "    cv.glmnet(x = selection %>% select(-valence) %>% as.matrix(), \n",
    "              y = selection %>% select(valence) %>% as.matrix(), \n",
    "              alpha = 1)\n",
    "plot(lasso_model, main = \"Figure 9. Lambda selection by CV with LASSO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8792d8-943f-46ed-bb1f-3030d92533a6",
   "metadata": {},
   "source": [
    "### Feature Selection using Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144c7db-86ba-4111-adaa-4632320089a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Feature selection using Ridge\n",
    "ridge_model <-\n",
    "    cv.glmnet(x = selection %>% select(-valence) %>% as.matrix(), \n",
    "              y = selection %>% select(valence) %>% as.matrix(), \n",
    "              alpha = 0)\n",
    "plot(ridge_model, main = \"Figure 10. Lambda selection by CV with Ridge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3d3df-ad77-408b-8c57-df0af31a5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model via ordinary least squares\n",
    "full_model <- lm(valence ~ ., data = selection)\n",
    "\n",
    "# LASSO model with lambda producing lowest MSE\n",
    "min_lasso_model <- glmnet(\n",
    "    x = selection %>% select(-valence) %>% as.matrix(),\n",
    "    y = selection %>% select(valence) %>% as.matrix(),\n",
    "    alpha = 1,\n",
    "    lambda = lasso_model$lambda.min)\n",
    "\n",
    "min_lasso_model.coef <- min_lasso_model$beta\n",
    "\n",
    "# Ridge model with lambda producing lowest MSE\n",
    "min_ridge_model <- glmnet(\n",
    "    x = selection %>% select(-valence) %>% as.matrix(),\n",
    "    y = selection %>% select(valence) %>% as.matrix(),\n",
    "    alpha = 0,\n",
    "    lambda = ridge_model$lambda.min)\n",
    "\n",
    "min_ridge_model.coef <- min_ridge_model$beta\n",
    "\n",
    "# Coefficients\n",
    "model_coefs <- cbind(\n",
    "  Full_OLS = coef(full_model),\n",
    "  LASSO_min = c(\n",
    "    min_lasso_model$a0,\n",
    "    as.vector(min_lasso_model.coef)\n",
    "  ),\n",
    "  Ridge_min = c(\n",
    "  min_ridge_model$a0,\n",
    "  as.vector(min_ridge_model.coef)\n",
    "  )\n",
    ")\n",
    "print(\"Table 6: Coefficients of the Features in our selected Model\")\n",
    "model_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3b9ba-685c-483e-8549-f42047592da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(full_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61719df6-5352-40ba-8fbc-bcac0c39b16a",
   "metadata": {},
   "source": [
    "Lasso and Ridge do not remove any features similar to the greedy selection methods, and the full model indicates that all variables are significant. Therefore, we will be keeping all of the predictive variables for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38d4a73-5093-418b-84ad-5ce6ffed7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multicollinearity in the predictors\n",
    "lasso_variables_vif <- \n",
    "   vif(lm(valence ~ popularity + acousticness + danceability + energy + instrumentalness +\n",
    "         liveness + loudness + speechiness + tempo, data = selection))\n",
    "\n",
    "lasso_variables_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c881e7-ff30-4055-b7f7-8b8bb8ab0533",
   "metadata": {},
   "source": [
    "While the highest VIFs correspond to the variables with the highest correlation (energy and loudness), there is no concerning presence of multicollinearity following James et al. (2013)'s method (only exceeding 5 or 10 poses problems). However, for our inference model, we will test to see if a model with energy & loudness may perform better or worse than without the variables to further prove that all variables are relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429738f-d4ae-4ddf-9458-26b0030dd418",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00fd903-a423-4c20-8d3a-3ec0706a83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset used to construct our models\n",
    "print(\"Table 7: Dataset for Inference\")\n",
    "head(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bf3f7-7f12-4771-baba-172325c15b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constructed using chosen covariates, without interaction\n",
    "spotify_model <- lm(valence ~ ., data = inference)\n",
    "spotify_model_summary = tidy(spotify_model, conf.int = TRUE) %>% mutate_if(is.numeric, round, 4)\n",
    "print(\"Table 8: Coefficients for Full Model (Without Interactions)\")\n",
    "spotify_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa02691-2937-4fe8-b272-d203e77d57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constructed using covariates, without loudness and energy nor interactions\n",
    "spotify_model_no_le <- lm(valence ~ popularity + acousticness + danceability + instrumentalness + liveness + speechiness + tempo, data = inference)\n",
    "spotify_model_no_le_summary <- tidy(spotify_model_no_le, conf.int = TRUE) %>% mutate_if(is.numeric, round, 4)\n",
    "print(\"Table 9: Coefficients for Model without Loudness and Energy (Without Interactions)\")\n",
    "spotify_model_no_le_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91a7fe-77a3-4b48-a53b-a60c2c9882ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table 10: Summary Statistics for the Full Model (Without Interactions)\")\n",
    "glance(spotify_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70cff67-6186-462f-bf0a-a3f8190972f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table 11: Summary Statistics for the Reduced Model (Without Interactions)\")\n",
    "glance(spotify_model_no_le)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0455e-f85c-4551-a813-84210c33254b",
   "metadata": {},
   "source": [
    "We see that the coefficient of determination is expectedly larger for the full model and that both perform better compared to the null model. However, we must use an ANOVA to assess whether the full model performs better than the nested one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f89676-d72a-4965-ba56-7bd5f11a7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table 12: Summary Statistics from F-test for Reduced vs. Full Model\")\n",
    "anova(spotify_model_no_le, spotify_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ba013-0020-4f8d-be04-6831bd2d0d32",
   "metadata": {},
   "source": [
    "We have evidence that the model with all variables performs significantly better than the model without the correlated variables loudness and energy. Thus, we conclude that the full model contains all relevant coefficients (popularity, acousticness, danceability, energy, instrumentalness, liveness, loudness, speechiness and tempo) and will use this to make our predictions.\n",
    "\n",
    "As our full and LASSO models report different coefficients, we must still assess which model has better prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a3f3e-42c6-4800-9313-6d830bfce56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_full_OLS <- predict(spotify_model,\n",
    "                              newx = inference %>% select(-valence) %>% as.matrix())\n",
    "\n",
    "min_lasso_model_infer <- glmnet(\n",
    "    x = inference %>% select(-valence) %>% as.matrix(),\n",
    "    y = inference %>% select(valence) %>% as.matrix(),\n",
    "    alpha = 1,\n",
    "    lambda = lasso_model$lambda.min)\n",
    "\n",
    "test_pred_LASSO_min <- predict(min_lasso_model_infer,\n",
    "                               newx = inference %>% select(-valence) %>% as.matrix())\n",
    "\n",
    "min_ridge_model_infer <- glmnet(\n",
    "    x = inference %>% select(-valence) %>% as.matrix(),\n",
    "    y = inference %>% select(valence) %>% as.matrix(),\n",
    "    alpha = 0,\n",
    "    lambda = ridge_model$lambda.min)\n",
    "\n",
    "test_pred_ridge_min <- predict(min_ridge_model_infer,\n",
    "                               newx = inference %>% select(-valence) %>% as.matrix())\n",
    "\n",
    "R_MSE_models <- rbind(tibble(\n",
    "  Model = \"OLS Full Regression\",\n",
    "  R_MSE = rmse(\n",
    "    preds = test_pred_full_OLS,\n",
    "    actuals = inference$valence\n",
    "  )\n",
    "),\n",
    "    tibble(\n",
    "    Model = \"LASSO Regression with minimum MSE\",\n",
    "    R_MSE = rmse(\n",
    "      preds = test_pred_LASSO_min,\n",
    "      actuals = inference$valence\n",
    "    )\n",
    "  ),\n",
    "    tibble(\n",
    "    Model = \"Ridge Regression with minimum MSE\",\n",
    "    R_MSE = rmse(\n",
    "      preds = test_pred_ridge_min,\n",
    "      actuals = inference$valence\n",
    "    )\n",
    "  )\n",
    ")\n",
    "print(\"Table 13: Root mean squared errors of the Full, LASSO and Ridge models\")\n",
    "R_MSE_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae4840-3796-4ff3-ba82-eb0dba8c725c",
   "metadata": {},
   "source": [
    "The OLS regression model has the lowest RMSE compared to the LASSO and Ridge models, thus we will use this to generate our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b27d1f-a0d4-4e54-9736-414cf7c3ba28",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565b74a-214f-4021-8c9a-3070de7096bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset used for prediction\n",
    "print(\"Table 14: Dataset for Prediction\")\n",
    "head(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa3164-bcbc-404c-bd4d-95ec3e9ef930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we get a vector of predicted values for our dataset using our model, \n",
    "predictions <- predict(spotify_model,\n",
    "                       newdata = prediction_df %>% select(-valence) %>% data.frame())\n",
    "pred_df <- tibble(\n",
    "    predicted_value = predictions,\n",
    "    actual_value = prediction_df$valence\n",
    ")\n",
    "print(\"Table 15: Predicted and Actual Values for Valence\")\n",
    "head(pred_df)\n",
    "predictions_plot = pred_df %>%\n",
    "    ggplot() +\n",
    "    geom_point(aes(y = predicted_value, x = actual_value)) + \n",
    "    labs() +\n",
    "    ggtitle(\"Figure 11. Predicted vs Actual Valence Value\")\n",
    "predictions_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc3978-8636-4975-9517-864ab9e00a86",
   "metadata": {},
   "source": [
    "Our model seems to loosely fit the data, with a similiar shape, however our model is not precise and seems to have high variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe7648-cc76-4e91-aa34-a9c0e2df8d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df %>%\n",
    "          mutate(residual = scale((actual_value - predicted_value)))\n",
    "residuals_plot = pred_df %>%\n",
    "                 ggplot() +\n",
    "                 geom_point(aes(x = predicted_value, y = residual)) + \n",
    "                 labs(title = \"Figure 12. Residuals-Fitted Value Plot\", y = \"Scaled Residual Value\", x = \"Predicted Value\")\n",
    "residuals_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c772902-4cc2-4f60-ab5c-4d13ec640aa0",
   "metadata": {},
   "source": [
    "Our residual plot has a clear linear trend, indicating homoscedasticity, and seems there may be variables affecting valence that our model is not accounting for, which might be the categorical variables we filtered out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a79f86-f423-4c7f-938e-25d2d872da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the RMSE for our final model\n",
    "inf_RMSE = R_MSE_models$R_MSE[2]\n",
    "pred_RMSE = mean((pred_df$actual_value - pred_df$predicted_value)^2) %>% sqrt() \n",
    "cat(\"Training root mean squared error:\", inf_RMSE, \"\\nTesting root mean squared error:\", pred_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fcb875-fc0b-421f-a44d-52c3b352ba46",
   "metadata": {},
   "source": [
    "Our inference RMSE (RMSE for the data we fit the model on) and prediction RMSE (for unknown data) are similiar, thus there is not any indication of overfitting or underfitting, and our model should generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c124cf-2e70-4b96-b949-3fea59592424",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### Findings\n",
    "We determined that popularity, acousticness, danceability, energy, instrumentalness, liveness, loudness, speechiness and tempo may contribute to a Spotify song’s emotional valence. This was not expected as we had thought that some variables may be irrelevant for our analysis, however all coefficients were returned as significant and neither greedy selection method nor the regularization methods LASSO and Ridge identified removable features (Table 6). We can interpret this as each feature may contribute to the valence value to some degree and thus a combination of these linear variables would be best suited for making predictions on new music.\n",
    "\n",
    "To select our inference model, we first compared the full model to a nested one without the highly correlated variables, loudness and energy, to see if the data had problems with multicollinearity, as we found that the variance inflation factors (VIF) for those variables were greater than the others. Loudness, a psychological measure of physical strength (amplitude), does logically relate to energy, which represents a perceptual measure of intensity and activity within a track; thus, we may expect energetic tracks that feel fast and noisy to also be typically louder. However, our F-test confirmed that the full model was significantly better than the reduced and therefore, the inclusion of both factors seems to fit the data better. This choice is also supported by James et al. ‘'s method (2013) which states that only VIFs exceeding 5 or 10 should pose problems for multicollinearity.\n",
    "\n",
    "We also compared the root mean squared error (RMSE) of the ordinary least squares (OLS) model to the LASSO and Ridge models to assess predictive performance, where the full OLS model returned the lowest error on unseen data (Table 13). We can interpret this as the full OLS generating coefficients that are less biased when compared to the other models, reducing the amount of overfitting on the training set. From our estimates, we also observe that with all other variables held constant, valence will increase by 0.707 for every increase by 1 in danceability and similarly decrease by 0.119 for every increase by 1 in speechiness on average (Table 7). As some variables are between 0 and 1, we can interpolate to calculate the effects on valence for decimal changes in these features.\n",
    "\n",
    "With the OLS model, we used a portion of our sample to generate predictions for unseen Spotify songs. We obtained a RMSE of approximately 0.198, thus our test predictions were generally about 0.20 off compared to the actual valence values. In other words, since valence is measured between 0 and 1, this means our model estimates have roughly 20% error on average. As our prediction (test) error is only 0.003 different from the inference (train) error, our model seems to generalize well to new data. However, this degree of error is still fairly large; a song’s valence could be predicted between 0.30 and 0.70 when its actual value is 0.50, thus leading us to assume its positivity or negativity when it is in fact neutral. Despite this, our other models produced similar RMSEs (Table 13), indicating that this level of predictive performance may be expected given the input variables used.\n",
    "\n",
    "### Strengths\n",
    "\n",
    "Our sample should be representative of all songs on Spotify as we do not expect the range of our input variables to change drastically (e.g. outside the bounds of human hearing) nor should there be significant deviations in valence values from one year to another or between regions of the world. Moreover, since we tested our inference model on a separate subsample, we assume that our model will perform reasonably well on other unseen Spotify data.\n",
    "\n",
    "### Impacts and Implications\n",
    "\n",
    "We made the decision to exclude categorical variables due to limits in computational power, however we cannot say for certain that these factors may not impact the valence. It is possible that genre could still be confounding; for example, certain feature values could affect the valence differentially if a song is classical or reggae given their different distributions (Figure 1). We also determined from Figure 12 that the data appears to be homoscedastic but biased, hence we may be missing another input variable in our analysis that may explain the diagonal pattern of the residuals. While valence is scaled between 0 and 1, the distribution is not precisely normal (Figure 5). Similarly, some input variables were skewed (ex. instrumentalness, liveness, loudness and speechiness). Therefore, we may receive better results from logarithmically transforming the feature values to normalize them prior to training the linear models, though these methods were not discussed in STAT 301.\n",
    "\n",
    "Since the method that Spotify uses to quantify valence remains unknown to the public, we hope that our results provide clarity on how humans perceive music. It seems that acousticness, danceability, energy and tempo contribute to making songs more cheerful, whereas popularity, instrumentalness, liveness, loudness and speechiness may be associated with more depressing music (Table 7). As our impressions appear to be based on a variety of components, it is unlikely that we can design tracks which emphasize certain features to produce the “happiest track ever” or vice versa. However, if you listen to music that is more energetic and loud, our analysis supports that you may prefer listening to positively valenced songs. From this assumption, it may be reasonable to make suggestions to Spotify users based on their most frequently played tracks’ feature values, though further human research would be required to confirm.\n",
    "\n",
    "### Future Questions\n",
    "\n",
    "- How does valence affect the popularity of Spotify tracks and their longevity to remain on the top of rankings charts?\n",
    "- Given the identified key contributors to valence, can these be attributed to making songs more or less likeable? Can we predict whether someone will enjoy a song based on these features?\n",
    "- Is Spotify suggesting new songs to users based on their valence? What ethical implications may this measure have on the emotions and/or mood of listeners?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295a0bb-42b1-4341-b8c7-362e6ecd4031",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Baldwin, C. L., & Lewis, B. A. (2017). Positive valence music restores executive control over \n",
    "sustained attention. PLOS ONE, 12(11). https://doi.org/10.1371/journal.pone.0186231 \n",
    "\n",
    "Business of Apps. (2021, October 29). Spotify revenue and Usage Statistics (2021). Business of Apps. \n",
    "Retrieved November 4, 2021, from https://www.businessofapps.com/data/spotify-statistics/. \n",
    "\n",
    "Hamidani, Z. (2019, July 23). Spotify tracks DB. Kaggle. Retrieved November 4, 2021, from \n",
    "https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db. \n",
    "\n",
    "Roy, M., Peretz, I., & Rainville, P. (2008). Emotional valence contributes to music-induced \n",
    "analgesia. Pain, 134(1), 140–147. https://doi.org/10.1016/j.pain.2007.04.003 \n",
    "\n",
    "Tajadura-Jiménez, A., Pantelidou, G., Rebacz, P., Västfjäll, D., & Tsakiris, M. (2011). I-space: \n",
    "The effects of emotional valence and source of music on interpersonal distance. PLOS ONE, \n",
    "6(10). https://doi.org/10.1371/journal.pone.0026083 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4e93a-4f71-4be1-b591-dc122d825776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
